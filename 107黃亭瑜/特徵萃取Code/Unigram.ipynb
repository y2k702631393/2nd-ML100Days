{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xml.etree.ElementTree as ET\n",
    "import html.parser\n",
    "from xml.sax.saxutils import unescape\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tree import Tree\n",
    "import string\n",
    "from nltk.util import bigrams,everygrams\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = open('CutData/Pseudo/NTF_200/Features_NTF2_1/Doc_NTF2_1.csv', 'r').read() #str\n",
    "doc_num = doc.split('\\n')  # str to list,以','切割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = ET.parse('Formspring/new_XMLMergedFile.xml')\n",
    "root = tree.getroot()\n",
    "symbol = {'!', '\"', '#', '$', '%', '&',\"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', \n",
    "          '=', '>', '?', '@', '[',  ']', '^', '_', '`', '{', '|', '}', '~', '\\''}\n",
    "html_parser = html.parser.HTMLParser()\n",
    "clean_txt = []\n",
    "c = []\n",
    "for child in root.iter(tag='TEXT'):\n",
    "    if child.attrib[\"id\"] in doc_num:\n",
    "        # 去除Q/A\n",
    "        find_q = html_parser.unescape(child.text)[0:3]    # 找前2個字母Q:\n",
    "        remove_q = html_parser.unescape(child.text).replace(find_q, '')    # 移除Q:\n",
    "        find_a = html_parser.unescape(child.text).split('<br>')[1][0:3]    # 1.由<br>切割後, 找第2部分的前2個字母A:\n",
    "        remove_a = remove_q.replace(find_a, '')    #移除A:\n",
    "        txt = remove_a.split('<br>') # 切Q/A\n",
    "        a =[]\n",
    "\n",
    "        for i in range(0,2):\n",
    "            sent = sent_tokenize(txt[i]) # list,斷句\n",
    "            for h in range(0,len(sent)):\n",
    "                re_url = re.sub(r'http://[a-zA-Z0-9./?%&_=-]*','' ,sent[h])\n",
    "                for x in symbol:\n",
    "                    if x in re_url:\n",
    "                        re_url = re_url.replace(x, '').strip()    #去除符號\n",
    "                word = word_tokenize(re_url)    # 斷詞\n",
    "    #             print(word)\n",
    "    #             big = list(bigrams(word))    # 2-ngram\n",
    "                a.extend(word)\n",
    "        b = list(set(a))    # 去除重複\n",
    "        b.sort(key=a.index)    # 排序\n",
    "    #     print(b)    \n",
    "    #     print('-----')\n",
    "        c.extend(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = list(set(c))     # 去除重複\n",
    "d.sort(key=c.index)    # 排序\n",
    "# print(d)# 全域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = ET.parse('Formspring/new_XMLMergedFile.xml')\n",
    "root = tree.getroot()\n",
    "symbol = {'!', '\"', '#', '$', '%', '&',\"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', \n",
    "          '=', '>', '?', '@', '[',  ']', '^', '_', '`', '{', '|', '}', '~', '\\''}\n",
    "html_parser = html.parser.HTMLParser()\n",
    "clean_txt = []\n",
    "j = 0\n",
    "exl = []\n",
    "for child in root.iter(tag='TEXT'):\n",
    "    if child.attrib[\"id\"] in doc_num:\n",
    "        # 去除Q/A\n",
    "        find_q = html_parser.unescape(child.text)[0:3]    # 找前2個字母Q:\n",
    "        remove_q = html_parser.unescape(child.text).replace(find_q, '')    # 移除Q:\n",
    "        find_a = html_parser.unescape(child.text).split('<br>')[1][0:3]    # 1.由<br>切割後, 找第2部分的前2個字母A:\n",
    "        remove_a = remove_q.replace(find_a, '')    #移除A:\n",
    "        txt = remove_a.split('<br>') # 切Q/A\n",
    "        a = []\n",
    "        for i in range(0,2):\n",
    "            sent = sent_tokenize(txt[i]) # list,斷句\n",
    "            for h in range(0,len(sent)):\n",
    "                re_url = re.sub(r'http://[a-zA-Z0-9./?%&_=-]*','' ,sent[h])\n",
    "                for x in symbol:\n",
    "                    if x in re_url:\n",
    "                        re_url = re_url.replace(x, '').strip()    #去除符號\n",
    "                word = word_tokenize(re_url)    # 斷詞\n",
    "    #             big = list(bigrams(word))    # 2-ngram\n",
    "                a.extend(word)\n",
    "\n",
    "        e = []\n",
    "        for q in d:\n",
    "            count = 0\n",
    "            for w in a:\n",
    "                if q == w:\n",
    "    #                 print(q)\n",
    "                    count+=1\n",
    "            e.append(count)\n",
    "    #         print(count)\n",
    "        j += 1\n",
    "    #     print(e)\n",
    "        exl.append([])\n",
    "        exl[j-1].append(\"D\" + str(child.attrib[\"id\"]))\n",
    "        for jj in e:\n",
    "            exl[j-1].append(jj)\n",
    "    #     print('------------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2296\n"
     ]
    }
   ],
   "source": [
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d.insert(0,'Doc') #120681組25702"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#計算小於2的改為空直\n",
    "for col in range(1,len(d)):\n",
    "    count = 0\n",
    "    for row in range(0,len(exl)):\n",
    "        count+=exl[row][col]\n",
    "#     print(count)\n",
    "    if (count<2):\n",
    "        for chg in range(0,len(exl)):\n",
    "            exl[chg][col] = '' #欄位變空值\n",
    "            d[col] = ''  #uni變空值\n",
    "# print(listbig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#不為空的uni放入list\n",
    "d = [remv for remv in d if remv !='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730\n"
     ]
    }
   ],
   "source": [
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(d) #4287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#不為空的欄位放入list\n",
    "new = []\n",
    "for g in range(0,len(exl)):\n",
    "    new.append([])\n",
    "    for k in exl[g]:\n",
    "#         print(k)\n",
    "#         print('--------')\n",
    "        if k != '':\n",
    "#             print(k)\n",
    "            new[g].append(k)\n",
    "# print(new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730\n"
     ]
    }
   ],
   "source": [
    "print(len(new[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('CutData/Pseudo/NTF_200/Features_NTF2_1/Unigram_NTF2_1.csv', 'w', encoding='UTF-8', newline='') as csvfile:\n",
    "  # 以空白分隔欄位，建立 CSV 檔寫入器\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(d)\n",
    "    writer.writerows(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
