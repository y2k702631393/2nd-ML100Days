{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from numpy import array\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title = ['Unigram+All','Logistic Regression','Random Forest','KNN','SVM','Decision Tree','Naive Bayes']\n",
    "row1 = ['Accuracy']\n",
    "row2 = ['Precision']\n",
    "row3 = ['Recall']\n",
    "row4 = ['Micro']\n",
    "row5 = ['Macro']\n",
    "row6 = ['Weighted']\n",
    "row7 = ['AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram = pd.read_csv('Pseudo3/Model_all/Unigram_MS.csv',encoding=\"UTF-8\") \n",
    "data = pd.read_excel('Pseudo3/Model_all/Data_MS.xlsx',encoding=\"UTF-8\") \n",
    "answer = pd.read_csv('Pseudo3/Model_all/Answer_MS.csv',encoding=\"UTF-8\")\n",
    "ntf = pd.read_excel('Pseudo3/NormalizedTF.xlsx',encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.merge(unigram, data, on='Doc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_result = result.values\n",
    "p_ntf = ntf.values\n",
    "y_answer = answer.values\n",
    "\n",
    "x = x_result[:,1:]\n",
    "ps = p_ntf[:]\n",
    "y = y_answer[:].ravel() \n",
    "\n",
    "b_Quantity = 50\n",
    "nb_Quantity = 100\n",
    "# scoring = ['accuracy', 'precision', 'recall', 'f1_micro', 'f1_macro', 'f1_weighted', 'roc_auc'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781039360094\n",
      "0.460279796053\n",
      "0.290221328098\n",
      "0.781039360094\n",
      "0.610125895203\n",
      "0.759526022449\n",
      "0.637312503133\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "acc = []\n",
    "f1 = []\n",
    "f2 = []\n",
    "f3 = []\n",
    "roc_auc = []\n",
    "p =[]\n",
    "r = []\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "for train_index, test_index in kf.split(x):\n",
    "   #     print(\" %s %s \" % (train_index, test_index))\n",
    "    doc = []\n",
    "    ans = []\n",
    "    rnd =[]\n",
    "    x_cut = []\n",
    "    y_cut = []\n",
    "    #x_test\n",
    "    x_test = np.array(x)[test_index]\n",
    "    #y_test\n",
    "    y_test = np.array(y)[test_index]\n",
    "    #P_train\n",
    "    p_train = np.array(ps)[train_index]\n",
    "    #PB_train，檔名/答案\n",
    "    p_B = sorted(p_train, key=lambda x:x[1], reverse=True)[:b_Quantity] #大到小排序`,取前B_Quantity個\n",
    "    for b_n in range(len(p_B)):\n",
    "        doc.append(p_B[b_n][0])\n",
    "        ans.append([p_B[b_n][0],1])\n",
    "    #PNB_train，檔名/答案\n",
    "    p_NB = sorted(p_train, key=lambda x:x[1])\n",
    "    for nb_n in range(len(p_NB)):\n",
    "        if(p_NB[nb_n][1] == 0.0):\n",
    "            rnd.append(p_NB[nb_n][0])\n",
    "    random.shuffle(rnd)\n",
    "    for rnd_n in range(0,nb_Quantity):\n",
    "        doc.append(rnd[rnd_n])\n",
    "        ans.append([rnd[rnd_n],0])\n",
    "    #x_train\n",
    "    for x_re in range(len(x_result)):\n",
    "        if(x_result[x_re][0] in doc):\n",
    "            x_cut.append(x_result[x_re])\n",
    "    x_t = array(x_cut)\n",
    "    x_train = x_t[:,1:]\n",
    "    #y_train\n",
    "    for y_re in range(len(x_t)):\n",
    "        for y_as in range(len(ans)):\n",
    "            if(x_t[y_re][0] == ans[y_as][0]):\n",
    "                y_cut.append(ans[y_as][1])\n",
    "    y_train = array(y_cut)\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(x_train,y_train)\n",
    "    \n",
    "    y_pred = np.array(lr.predict(x_test))\n",
    "    y_score = np.array(lr.predict_proba(x_test)[:,1])\n",
    "    y_test = np.array(y_test) #y_true\n",
    "    acc.append(lr.score(x_test,y_test))\n",
    "    f1.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    f2.append(f1_score(y_test, y_pred, average='micro'))\n",
    "    f3.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, y_score))\n",
    "    p.append(precision_score(y_test, y_pred))\n",
    "    r.append(recall_score(y_test, y_pred))\n",
    "accuracy=0\n",
    "weighted=0\n",
    "micro=0\n",
    "macro=0\n",
    "auc=0\n",
    "precision = 0\n",
    "recall = 0\n",
    "\n",
    "for i in range(0,10):\n",
    "    accuracy=accuracy+acc[i]\n",
    "    weighted=weighted+f1[i]\n",
    "    micro=micro+f2[i]\n",
    "    macro=macro+f3[i]\n",
    "    precision=precision+p[i]\n",
    "    recall=recall+r[i]\n",
    "    auc=auc+roc_auc[i]\n",
    "    \n",
    "accuracy=accuracy/10\n",
    "weighted=weighted/10\n",
    "micro=micro/10\n",
    "macro=macro/10\n",
    "auc=auc/10\n",
    "precision=precision/10\n",
    "recall=recall/10\n",
    "\n",
    "#accuracy\n",
    "print(\"{:.12f}\".format(accuracy))\n",
    "row1.append((\"{:.12f}\".format(accuracy)))\n",
    "#precision\n",
    "print(\"{:.12f}\".format(precision))\n",
    "row2.append((\"{:.12f}\".format(precision)))\n",
    "#recall\n",
    "print(\"{:.12f}\".format(recall))\n",
    "row3.append((\"{:.12f}\".format(recall)))\n",
    "#f-measure\n",
    "print(\"{:.12f}\".format(micro))\n",
    "row4.append((\"{:.12f}\".format(micro)))\n",
    "print(\"{:.12f}\".format(macro))\n",
    "row5.append((\"{:.12f}\".format(macro)))\n",
    "print(\"{:.12f}\".format(weighted))\n",
    "row6.append((\"{:.12f}\".format(weighted)))\n",
    "#auc\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(y,pred,pos_label=2)\n",
    "#metrics.auc(fpr, tpr)\n",
    "print(\"{:.12f}\".format(auc))\n",
    "row7.append((\"{:.12f}\".format(auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781046676096\n",
      "0.435624186615\n",
      "0.157973537396\n",
      "0.781046676096\n",
      "0.548035500478\n",
      "0.735904674357\n",
      "0.625485354777\n"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifier\n",
    "acc = []\n",
    "f1 = []\n",
    "f2 = []\n",
    "f3 = []\n",
    "roc_auc = []\n",
    "p =[]\n",
    "r = []\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "for train_index, test_index in kf.split(x):\n",
    "   #     print(\" %s %s \" % (train_index, test_index))\n",
    "    doc = []\n",
    "    ans = []\n",
    "    rnd =[]\n",
    "    x_cut = []\n",
    "    y_cut = []\n",
    "    #x_test\n",
    "    x_test = np.array(x)[test_index]\n",
    "    #y_test\n",
    "    y_test = np.array(y)[test_index]\n",
    "    #P_train\n",
    "    p_train = np.array(ps)[train_index]\n",
    "    #PB_train，檔名/答案\n",
    "    p_B = sorted(p_train, key=lambda x:x[1], reverse=True)[:b_Quantity] #大到小排序`,取前B_Quantity個\n",
    "    for b_n in range(len(p_B)):\n",
    "        doc.append(p_B[b_n][0])\n",
    "        ans.append([p_B[b_n][0],1])\n",
    "    #PNB_train，檔名/答案\n",
    "    p_NB = sorted(p_train, key=lambda x:x[1])\n",
    "    for nb_n in range(len(p_NB)):\n",
    "        if(p_NB[nb_n][1] == 0.0):\n",
    "            rnd.append(p_NB[nb_n][0])\n",
    "    random.shuffle(rnd)\n",
    "    for rnd_n in range(0,nb_Quantity):\n",
    "        doc.append(rnd[rnd_n])\n",
    "        ans.append([rnd[rnd_n],0])\n",
    "    #x_train\n",
    "    for x_re in range(len(x_result)):\n",
    "        if(x_result[x_re][0] in doc):\n",
    "            x_cut.append(x_result[x_re])\n",
    "    x_t = array(x_cut)\n",
    "    x_train = x_t[:,1:]\n",
    "    #y_train\n",
    "    for y_re in range(len(x_t)):\n",
    "        for y_as in range(len(ans)):\n",
    "            if(x_t[y_re][0] == ans[y_as][0]):\n",
    "                y_cut.append(ans[y_as][1])\n",
    "    y_train = array(y_cut)\n",
    "    \n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(x_train,y_train)\n",
    "    \n",
    "    y_pred = np.array(rfc.predict(x_test)) #y_score\n",
    "    y_score = np.array(rfc.predict_proba(x_test)[:,1])\n",
    "    y_test = np.array(y_test) #y_true\n",
    "    \n",
    "    acc.append(rfc.score(x_test,y_test))\n",
    "    f1.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    f2.append(f1_score(y_test, y_pred, average='micro'))\n",
    "    f3.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, y_score))\n",
    "    p.append(precision_score(y_test, y_pred))\n",
    "    r.append(recall_score(y_test, y_pred))\n",
    "accuracy=0\n",
    "weighted=0\n",
    "micro=0\n",
    "macro=0\n",
    "auc=0\n",
    "precision = 0\n",
    "recall = 0\n",
    "\n",
    "for i in range(0,10):\n",
    "    accuracy=accuracy+acc[i]\n",
    "    weighted=weighted+f1[i]\n",
    "    micro=micro+f2[i]\n",
    "    macro=macro+f3[i]\n",
    "    precision=precision+p[i]\n",
    "    recall=recall+r[i]\n",
    "    auc=auc+roc_auc[i]   \n",
    "\n",
    "accuracy=accuracy/10\n",
    "weighted=weighted/10\n",
    "micro=micro/10\n",
    "macro=macro/10\n",
    "auc=auc/10\n",
    "precision=precision/10\n",
    "recall=recall/10\n",
    "\n",
    "#accuracy\n",
    "print(\"{:.12f}\".format(accuracy))\n",
    "row1.append((\"{:.12f}\".format(accuracy)))\n",
    "#precision\n",
    "print(\"{:.12f}\".format(precision))\n",
    "row2.append((\"{:.12f}\".format(precision)))\n",
    "#recall\n",
    "print(\"{:.12f}\".format(recall))\n",
    "row3.append((\"{:.12f}\".format(recall)))\n",
    "#f-measure\n",
    "print(\"{:.12f}\".format(micro))\n",
    "row4.append((\"{:.12f}\".format(micro)))\n",
    "print(\"{:.12f}\".format(macro))\n",
    "row5.append((\"{:.12f}\".format(macro)))\n",
    "print(\"{:.12f}\".format(weighted))\n",
    "row6.append((\"{:.12f}\".format(weighted)))\n",
    "#auc\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(y,pred,pos_label=2)\n",
    "#metrics.auc(fpr, tpr)\n",
    "print(\"{:.12f}\".format(auc))\n",
    "row7.append((\"{:.12f}\".format(auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.705606496610\n",
      "0.270585308828\n",
      "0.226521260647\n",
      "0.705606496610\n",
      "0.530350336360\n",
      "0.696590988884\n",
      "0.523169491292\n"
     ]
    }
   ],
   "source": [
    "#KNeighborsClassifier\n",
    "acc = []\n",
    "f1 = []\n",
    "f2 = []\n",
    "f3 = []\n",
    "roc_auc = []\n",
    "p =[]\n",
    "r = []\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "for train_index, test_index in kf.split(x):\n",
    "   #     print(\" %s %s \" % (train_index, test_index))\n",
    "    doc = []\n",
    "    ans = []\n",
    "    rnd =[]\n",
    "    x_cut = []\n",
    "    y_cut = []\n",
    "    #x_test\n",
    "    x_test = np.array(x)[test_index]\n",
    "    #y_test\n",
    "    y_test = np.array(y)[test_index]\n",
    "    #P_train\n",
    "    p_train = np.array(ps)[train_index]\n",
    "    #PB_train，檔名/答案\n",
    "    p_B = sorted(p_train, key=lambda x:x[1], reverse=True)[:b_Quantity] #大到小排序`,取前B_Quantity個\n",
    "    for b_n in range(len(p_B)):\n",
    "        doc.append(p_B[b_n][0])\n",
    "        ans.append([p_B[b_n][0],1])\n",
    "    #PNB_train，檔名/答案\n",
    "    p_NB = sorted(p_train, key=lambda x:x[1])\n",
    "    for nb_n in range(len(p_NB)):\n",
    "        if(p_NB[nb_n][1] == 0.0):\n",
    "            rnd.append(p_NB[nb_n][0])\n",
    "    random.shuffle(rnd)\n",
    "    for rnd_n in range(0,nb_Quantity):\n",
    "        doc.append(rnd[rnd_n])\n",
    "        ans.append([rnd[rnd_n],0])\n",
    "    #x_train\n",
    "    for x_re in range(len(x_result)):\n",
    "        if(x_result[x_re][0] in doc):\n",
    "            x_cut.append(x_result[x_re])\n",
    "    x_t = array(x_cut)\n",
    "    x_train = x_t[:,1:]\n",
    "    #y_train\n",
    "    for y_re in range(len(x_t)):\n",
    "        for y_as in range(len(ans)):\n",
    "            if(x_t[y_re][0] == ans[y_as][0]):\n",
    "                y_cut.append(ans[y_as][1])\n",
    "    y_train = array(y_cut)\n",
    "    \n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(x_train,y_train)\n",
    "    \n",
    "    y_pred = np.array(knn.predict(x_test)) #y_score\n",
    "    y_score = np.array(knn.predict_proba(x_test)[:,1])\n",
    "    y_test = np.array(y_test) #y_true\n",
    "    \n",
    "    acc.append(knn.score(x_test,y_test))\n",
    "    f1.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    f2.append(f1_score(y_test, y_pred, average='micro'))\n",
    "    f3.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, y_score))\n",
    "    p.append(precision_score(y_test, y_pred))\n",
    "    r.append(recall_score(y_test, y_pred))\n",
    "accuracy=0\n",
    "weighted=0\n",
    "micro=0\n",
    "macro=0\n",
    "auc=0\n",
    "precision = 0\n",
    "recall = 0\n",
    "\n",
    "for i in range(0,10):\n",
    "    accuracy=accuracy+acc[i]\n",
    "    weighted=weighted+f1[i]\n",
    "    micro=micro+f2[i]\n",
    "    macro=macro+f3[i]\n",
    "    precision=precision+p[i]\n",
    "    recall=recall+r[i]\n",
    "    auc=auc+roc_auc[i]\n",
    "    \n",
    "accuracy=accuracy/10\n",
    "weighted=weighted/10\n",
    "micro=micro/10\n",
    "macro=macro/10\n",
    "auc=auc/10\n",
    "precision=precision/10\n",
    "recall=recall/10\n",
    "\n",
    "#accuracy\n",
    "print(\"{:.12f}\".format(accuracy))\n",
    "row1.append((\"{:.12f}\".format(accuracy)))\n",
    "#precision\n",
    "print(\"{:.12f}\".format(precision))\n",
    "row2.append((\"{:.12f}\".format(precision)))\n",
    "#recall\n",
    "print(\"{:.12f}\".format(recall))\n",
    "row3.append((\"{:.12f}\".format(recall)))\n",
    "#f-measure\n",
    "print(\"{:.12f}\".format(micro))\n",
    "row4.append((\"{:.12f}\".format(micro)))\n",
    "print(\"{:.12f}\".format(macro))\n",
    "row5.append((\"{:.12f}\".format(macro)))\n",
    "print(\"{:.12f}\".format(weighted))\n",
    "row6.append((\"{:.12f}\".format(weighted)))\n",
    "#auc\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(y,pred,pos_label=2)\n",
    "#metrics.auc(fpr, tpr)\n",
    "print(\"{:.12f}\".format(auc))\n",
    "row7.append((\"{:.12f}\".format(auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754423742867\n",
      "0.407476046059\n",
      "0.376876456849\n",
      "0.754423742867\n",
      "0.617240406950\n",
      "0.749712685797\n",
      "0.656625429037\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "acc = []\n",
    "f1 = []\n",
    "f2 = []\n",
    "f3 = []\n",
    "roc_auc = []\n",
    "p =[]\n",
    "r = []\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "for train_index, test_index in kf.split(x):\n",
    "   #     print(\" %s %s \" % (train_index, test_index))\n",
    "    doc = []\n",
    "    ans = []\n",
    "    rnd =[]\n",
    "    x_cut = []\n",
    "    y_cut = []\n",
    "    #x_test\n",
    "    x_test = np.array(x)[test_index]\n",
    "    #y_test\n",
    "    y_test = np.array(y)[test_index]\n",
    "    #P_train\n",
    "    p_train = np.array(ps)[train_index]\n",
    "    #PB_train，檔名/答案\n",
    "    p_B = sorted(p_train, key=lambda x:x[1], reverse=True)[:b_Quantity] #大到小排序`,取前B_Quantity個\n",
    "    for b_n in range(len(p_B)):\n",
    "        doc.append(p_B[b_n][0])\n",
    "        ans.append([p_B[b_n][0],1])\n",
    "    #PNB_train，檔名/答案\n",
    "    p_NB = sorted(p_train, key=lambda x:x[1])\n",
    "    for nb_n in range(len(p_NB)):\n",
    "        if(p_NB[nb_n][1] == 0.0):\n",
    "            rnd.append(p_NB[nb_n][0])\n",
    "    random.shuffle(rnd)\n",
    "    for rnd_n in range(0,nb_Quantity):\n",
    "        doc.append(rnd[rnd_n])\n",
    "        ans.append([rnd[rnd_n],0])\n",
    "    #x_train\n",
    "    for x_re in range(len(x_result)):\n",
    "        if(x_result[x_re][0] in doc):\n",
    "            x_cut.append(x_result[x_re])\n",
    "    x_t = array(x_cut)\n",
    "    x_train = x_t[:,1:]\n",
    "    #y_train\n",
    "    for y_re in range(len(x_t)):\n",
    "        for y_as in range(len(ans)):\n",
    "            if(x_t[y_re][0] == ans[y_as][0]):\n",
    "                y_cut.append(ans[y_as][1])\n",
    "    y_train = array(y_cut)\n",
    "    \n",
    "    sv = svm.SVC(kernel='linear')\n",
    "    sv.fit(x_train,y_train)\n",
    "    \n",
    "    y_pred = np.array(sv.predict(x_test)) #y_score\n",
    "    y_score = np.array(sv.decision_function(x_test))\n",
    "    y_test = np.array(y_test) #y_true\n",
    "    \n",
    "    acc.append(sv.score(x_test,y_test))\n",
    "    f1.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    f2.append(f1_score(y_test, y_pred, average='micro'))\n",
    "    f3.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, y_score))\n",
    "    p.append(precision_score(y_test, y_pred))\n",
    "    r.append(recall_score(y_test, y_pred))\n",
    "accuracy=0\n",
    "weighted=0\n",
    "micro=0\n",
    "macro=0\n",
    "auc=0\n",
    "precision = 0\n",
    "recall = 0\n",
    "\n",
    "for i in range(0,10):\n",
    "    accuracy=accuracy+acc[i]\n",
    "    weighted=weighted+f1[i]\n",
    "    micro=micro+f2[i]\n",
    "    macro=macro+f3[i]\n",
    "    precision=precision+p[i]\n",
    "    recall=recall+r[i]\n",
    "    auc=auc+roc_auc[i]\n",
    "    \n",
    "accuracy=accuracy/10\n",
    "weighted=weighted/10\n",
    "micro=micro/10\n",
    "macro=macro/10\n",
    "auc=auc/10\n",
    "precision=precision/10\n",
    "recall=recall/10\n",
    "\n",
    "#accuracy\n",
    "print(\"{:.12f}\".format(accuracy))\n",
    "row1.append((\"{:.12f}\".format(accuracy)))\n",
    "#precision\n",
    "print(\"{:.12f}\".format(precision))\n",
    "row2.append((\"{:.12f}\".format(precision)))\n",
    "#recall\n",
    "print(\"{:.12f}\".format(recall))\n",
    "row3.append((\"{:.12f}\".format(recall)))\n",
    "#f-measure\n",
    "print(\"{:.12f}\".format(micro))\n",
    "row4.append((\"{:.12f}\".format(micro)))\n",
    "print(\"{:.12f}\".format(macro))\n",
    "row5.append((\"{:.12f}\".format(macro)))\n",
    "print(\"{:.12f}\".format(weighted))\n",
    "row6.append((\"{:.12f}\".format(weighted)))\n",
    "#auc\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(y,pred,pos_label=2)\n",
    "#metrics.auc(fpr, tpr)\n",
    "print(\"{:.12f}\".format(auc))\n",
    "row7.append((\"{:.12f}\".format(auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.680966200068\n",
      "0.341328645657\n",
      "0.559376109959\n",
      "0.680966200068\n",
      "0.601046082454\n",
      "0.704332509117\n",
      "0.636561951357\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeClassifier\n",
    "acc = []\n",
    "f1 = []\n",
    "f2 = []\n",
    "f3 = []\n",
    "roc_auc = []\n",
    "p =[]\n",
    "r = []\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "for train_index, test_index in kf.split(x):\n",
    "   #     print(\" %s %s \" % (train_index, test_index))\n",
    "    doc = []\n",
    "    ans = []\n",
    "    rnd =[]\n",
    "    x_cut = []\n",
    "    y_cut = []\n",
    "    #x_test\n",
    "    x_test = np.array(x)[test_index]\n",
    "    #y_test\n",
    "    y_test = np.array(y)[test_index]\n",
    "    #P_train\n",
    "    p_train = np.array(ps)[train_index]\n",
    "    #PB_train，檔名/答案\n",
    "    p_B = sorted(p_train, key=lambda x:x[1], reverse=True)[:b_Quantity] #大到小排序`,取前B_Quantity個\n",
    "    for b_n in range(len(p_B)):\n",
    "        doc.append(p_B[b_n][0])\n",
    "        ans.append([p_B[b_n][0],1])\n",
    "    #PNB_train，檔名/答案\n",
    "    p_NB = sorted(p_train, key=lambda x:x[1])\n",
    "    for nb_n in range(len(p_NB)):\n",
    "        if(p_NB[nb_n][1] == 0.0):\n",
    "            rnd.append(p_NB[nb_n][0])\n",
    "    random.shuffle(rnd)\n",
    "    for rnd_n in range(0,nb_Quantity):\n",
    "        doc.append(rnd[rnd_n])\n",
    "        ans.append([rnd[rnd_n],0])\n",
    "    #x_train\n",
    "    for x_re in range(len(x_result)):\n",
    "        if(x_result[x_re][0] in doc):\n",
    "            x_cut.append(x_result[x_re])\n",
    "    x_t = array(x_cut)\n",
    "    x_train = x_t[:,1:]\n",
    "    #y_train\n",
    "    for y_re in range(len(x_t)):\n",
    "        for y_as in range(len(ans)):\n",
    "            if(x_t[y_re][0] == ans[y_as][0]):\n",
    "                y_cut.append(ans[y_as][1])\n",
    "    y_train = array(y_cut)\n",
    "    \n",
    "    dtc = DecisionTreeClassifier() \n",
    "    dtc.fit(x_train,y_train)\n",
    "    \n",
    "    y_pred = np.array(dtc.predict(x_test)) #y_score\n",
    "    y_score = np.array(dtc.predict_proba(x_test)[:,1])\n",
    "    y_test = np.array(y_test) #y_true\n",
    "    \n",
    "    acc.append(dtc.score(x_test,y_test))\n",
    "    f1.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    f2.append(f1_score(y_test, y_pred, average='micro'))\n",
    "    f3.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, y_score))\n",
    "    p.append(precision_score(y_test, y_pred))\n",
    "    r.append(recall_score(y_test, y_pred))\n",
    "accuracy=0\n",
    "weighted=0\n",
    "micro=0\n",
    "macro=0\n",
    "auc=0\n",
    "precision = 0\n",
    "recall = 0\n",
    "\n",
    "for i in range(0,10):\n",
    "    accuracy=accuracy+acc[i]\n",
    "    weighted=weighted+f1[i]\n",
    "    micro=micro+f2[i]\n",
    "    macro=macro+f3[i]\n",
    "    precision=precision+p[i]\n",
    "    recall=recall+r[i]\n",
    "    auc=auc+roc_auc[i]\n",
    "    \n",
    "accuracy=accuracy/10\n",
    "weighted=weighted/10\n",
    "micro=micro/10\n",
    "macro=macro/10\n",
    "auc=auc/10\n",
    "precision=precision/10\n",
    "recall=recall/10\n",
    "\n",
    "#accuracy\n",
    "print(\"{:.12f}\".format(accuracy))\n",
    "row1.append((\"{:.12f}\".format(accuracy)))\n",
    "#precision\n",
    "print(\"{:.12f}\".format(precision))\n",
    "row2.append((\"{:.12f}\".format(precision)))\n",
    "#recall\n",
    "print(\"{:.12f}\".format(recall))\n",
    "row3.append((\"{:.12f}\".format(recall)))\n",
    "#f-measure\n",
    "print(\"{:.12f}\".format(micro))\n",
    "row4.append((\"{:.12f}\".format(micro)))\n",
    "print(\"{:.12f}\".format(macro))\n",
    "row5.append((\"{:.12f}\".format(macro)))\n",
    "print(\"{:.12f}\".format(weighted))\n",
    "row6.append((\"{:.12f}\".format(weighted)))\n",
    "#auc\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(y,pred,pos_label=2)\n",
    "#metrics.auc(fpr, tpr)\n",
    "print(\"{:.12f}\".format(auc))\n",
    "row7.append((\"{:.12f}\".format(auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.696217626689\n",
      "0.337709969873\n",
      "0.458067208742\n",
      "0.696217626689\n",
      "0.591977843785\n",
      "0.711362405992\n",
      "0.609274938372\n"
     ]
    }
   ],
   "source": [
    "#GaussianNB\n",
    "acc = []\n",
    "f1 = []\n",
    "f2 = []\n",
    "f3 = []\n",
    "roc_auc = []\n",
    "p =[]\n",
    "r = []\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "for train_index, test_index in kf.split(x):\n",
    "   #     print(\" %s %s \" % (train_index, test_index))\n",
    "    doc = []\n",
    "    ans = []\n",
    "    rnd =[]\n",
    "    x_cut = []\n",
    "    y_cut = []\n",
    "    #x_test\n",
    "    x_test = np.array(x)[test_index]\n",
    "    #y_test\n",
    "    y_test = np.array(y)[test_index]\n",
    "    #P_train\n",
    "    p_train = np.array(ps)[train_index]\n",
    "    #PB_train，檔名/答案\n",
    "    p_B = sorted(p_train, key=lambda x:x[1], reverse=True)[:b_Quantity] #大到小排序`,取前B_Quantity個\n",
    "    for b_n in range(len(p_B)):\n",
    "        doc.append(p_B[b_n][0])\n",
    "        ans.append([p_B[b_n][0],1])\n",
    "    #PNB_train，檔名/答案\n",
    "    p_NB = sorted(p_train, key=lambda x:x[1])\n",
    "    for nb_n in range(len(p_NB)):\n",
    "        if(p_NB[nb_n][1] == 0.0):\n",
    "            rnd.append(p_NB[nb_n][0])\n",
    "    random.shuffle(rnd)\n",
    "    for rnd_n in range(0,nb_Quantity):\n",
    "        doc.append(rnd[rnd_n])\n",
    "        ans.append([rnd[rnd_n],0])\n",
    "    #x_train\n",
    "    for x_re in range(len(x_result)):\n",
    "        if(x_result[x_re][0] in doc):\n",
    "            x_cut.append(x_result[x_re])\n",
    "    x_t = array(x_cut)\n",
    "    x_train = x_t[:,1:]\n",
    "    #y_train\n",
    "    for y_re in range(len(x_t)):\n",
    "        for y_as in range(len(ans)):\n",
    "            if(x_t[y_re][0] == ans[y_as][0]):\n",
    "                y_cut.append(ans[y_as][1])\n",
    "    y_train = array(y_cut)\n",
    "    \n",
    "    gnb = GaussianNB() \n",
    "    gnb.fit(x_train,y_train)\n",
    "    \n",
    "    y_pred = np.array(gnb.predict(x_test)) #y_score\n",
    "    y_score = np.array(gnb.predict_proba(x_test)[:,1])\n",
    "    y_test = np.array(y_test) #y_true\n",
    "    \n",
    "    acc.append(gnb.score(x_test,y_test))\n",
    "    f1.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    f2.append(f1_score(y_test, y_pred, average='micro'))\n",
    "    f3.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, y_score))\n",
    "    p.append(precision_score(y_test, y_pred))\n",
    "    r.append(recall_score(y_test, y_pred))\n",
    "accuracy=0\n",
    "weighted=0\n",
    "micro=0\n",
    "macro=0\n",
    "auc=0\n",
    "precision = 0\n",
    "recall = 0\n",
    "\n",
    "for i in range(0,10):\n",
    "    accuracy=accuracy+acc[i]\n",
    "    weighted=weighted+f1[i]\n",
    "    micro=micro+f2[i]\n",
    "    macro=macro+f3[i]\n",
    "    precision=precision+p[i]\n",
    "    recall=recall+r[i]\n",
    "    auc=auc+roc_auc[i]\n",
    "    \n",
    "accuracy=accuracy/10\n",
    "weighted=weighted/10\n",
    "micro=micro/10\n",
    "macro=macro/10\n",
    "auc=auc/10\n",
    "precision=precision/10\n",
    "recall=recall/10\n",
    "\n",
    "#accuracy\n",
    "print(\"{:.12f}\".format(accuracy))\n",
    "row1.append((\"{:.12f}\".format(accuracy)))\n",
    "#precision\n",
    "print(\"{:.12f}\".format(precision))\n",
    "row2.append((\"{:.12f}\".format(precision)))\n",
    "#recall\n",
    "print(\"{:.12f}\".format(recall))\n",
    "row3.append((\"{:.12f}\".format(recall)))\n",
    "#f-measure\n",
    "print(\"{:.12f}\".format(micro))\n",
    "row4.append((\"{:.12f}\".format(micro)))\n",
    "print(\"{:.12f}\".format(macro))\n",
    "row5.append((\"{:.12f}\".format(macro)))\n",
    "print(\"{:.12f}\".format(weighted))\n",
    "row6.append((\"{:.12f}\".format(weighted)))\n",
    "#auc\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(y,pred,pos_label=2)\n",
    "#metrics.auc(fpr, tpr)\n",
    "print(\"{:.12f}\".format(auc))\n",
    "row7.append((\"{:.12f}\".format(auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Pseudo3/NTF/NTF510.csv', 'a', encoding='UTF-8', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(title)\n",
    "    writer.writerow(row1)\n",
    "    writer.writerow(row2)\n",
    "    writer.writerow(row3)\n",
    "    writer.writerow(row4)\n",
    "    writer.writerow(row5)\n",
    "    writer.writerow(row6)\n",
    "    writer.writerow(row7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
